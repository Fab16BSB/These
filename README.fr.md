# DÃ©tection dâ€™anomalies en temps rÃ©el dans un flux vidÃ©o

## ğŸ“Œ Contexte  

Jâ€™ai rÃ©alisÃ© une **thÃ¨se CIFRE** (Convention Industrielle de Formation par la Recherche) dâ€™une durÃ©e de **3 ans** (du 4 dÃ©cembre 2019 au 4 dÃ©cembre 2022), intitulÃ©e **_DÃ©tection dâ€™anomalies en temps rÃ©el dans un flux vidÃ©o_**.  

Durant cette pÃ©riode, jâ€™ai occupÃ© le poste de **chercheur** au sein de la startup [**Othello** ğŸš€](http://www.othello.group), ce qui mâ€™a permis de mener mes travaux de recherche directement en entreprise tout en Ã©tant encadrÃ© par le **Laboratoire dâ€™Intelligence Artificielle et SÃ©mantique des DonnÃ©es (LIASD)** ğŸ§  de lâ€™UniversitÃ© **Paris 8** ğŸ“š, favorisant ainsi le transfert de connaissances entre le monde industriel et la recherche ğŸ¤.

---

## ğŸ¯ Objectif  

Lâ€™objectif de ce projet Ã©tait de dÃ©velopper une solution de **dÃ©tection dâ€™anomalies par intelligence artificielle** ğŸ¤–, dans le cadre de lâ€™appel Ã  projet visant Ã  **assurer la sÃ©curitÃ© des Jeux Olympiques de Paris 2024** ğŸ….
Parmi les contraintes imposÃ©es :  
- Le modÃ¨le devait fonctionner **en temps rÃ©el** afin de permettre une intervention rapide et ainsi garantir la sÃ©curitÃ© et la sÃ»retÃ© des personnes impliquÃ©es.
  
- Les ressources disponibles Ã©taient limitÃ©es : **pas dâ€™accÃ¨s Ã  un serveur GPU** ni Ã  de **vÃ©ritables camÃ©ras de surveillance**, ce qui a renforcÃ© le dÃ©fi technique du projet.
  
- Le modÃ¨le devait Ãªtre **lÃ©ger et optimisÃ©**, de sorte Ã  pouvoir fonctionner sans nÃ©cessiter un serveur GPU puissant, ce qui Ã©tait essentiel compte tenu des ressources limitÃ©es.  

---

## ğŸ’¡ Postulat  

En tant quâ€™humains, nous pouvons facilement identifier une situation anormale dans une scÃ¨ne ou une vidÃ©o :  
- un **incendie** grÃ¢ce Ã  la prÃ©sence de fumÃ©e ou de flammes ğŸ”¥  
- une **bagarre** en observant les interactions entre plusieurs personnes ğŸ‘¥  
- un **accident de la route** en surveillant les vÃ©hicules ğŸš—  
- un **danger** potentiel en repÃ©rant une arme blanche ou Ã  feu ğŸ—¡ï¸ğŸ”«  
- De plus, un accident de la route **ne peut pas se produire** si aucun vÃ©hicule nâ€™est visible Ã  lâ€™Ã©cran.

Ces observations m'ont inspirÃ©s Ã  combiner dans ce projet :  
1. **Analyse spatiale** : dÃ©tection dâ€™objets et de poses humaines potentiellement suspectes   
2. **Analyse temporelle** : suivi des actions des objets et des individus dans le temps    

Lâ€™objectif est de crÃ©er une architecture combinant **analyse spatiale et temporelle**, reproduisant, de maniÃ¨re simplifiÃ©e, la faÃ§on dont les humains interprÃ¨tent une scÃ¨ne en observant les objets et leur dynamique pour comprendre la situation dans son ensemble dans le but dâ€™Ã©valuer si cette approche peut surpasser les mÃ©thodes classiques.

---

## âš™ï¸ Environnement technique  

L'esmble du projet a Ã©tÃ© dÃ©veloppÃ© sur un ordinateur portable fourni par lâ€™entreprise, Ã©quipÃ© des composants suivants :  
- **MÃ©moire RAM :** 32 Go  
- **Processeur :** Intel Core i9, 16 cÅ“urs cadencÃ©s Ã  2,3 GHz  
- **Carte graphique :** Nvidia GeForce RTX 2080 avec 8 Go de RAM dÃ©diÃ©e  

CÃ´tÃ© logiciel, le dÃ©veloppement et lâ€™entraÃ®nement des modÃ¨les ont Ã©tÃ© rÃ©alisÃ©s avec :  
- **Python**  
- **Keras** pour la conception et lâ€™entraÃ®nement des modÃ¨les dâ€™intelligence artificielle

---

## ğŸ“Š Jeu de donnÃ©es  

### 1ï¸âƒ£ VidÃ©os pour la dÃ©tection dâ€™anomalies 

Aucun jeu de donnÃ©es public nâ€™Ã©tait suffisamment adaptÃ© pour entraÃ®ner efficacement notre modÃ¨le :  
- Manque de volume et de variÃ©tÃ©  
- QualitÃ© insuffisante  
- PrÃ©sence dâ€™anomalies ne reprÃ©sentant pas de consÃ©quences directes sur la sÃ©curitÃ© et la sÃ»retÃ© des personnes impliquÃ©es  

Nous avons donc conÃ§u notre propre jeu de donnÃ©es.

*âš ï¸Ce je de donnÃ©e est propriÃ©taire et ne sera pas partagÃ© ni communiquÃ©.âš ï¸*  

#### ğŸ·ï¸ Classes et rÃ©partition

Le jeu de donnÃ©es est composÃ© de **4 classes** :  
- **Fight** (bagarre)  
- **Shooting** (coup de feu)  
- **Fire** (incendie)  
- **Normal** (aucun problÃ¨me dÃ©tectÃ©)  

Il est **dÃ©sÃ©quilibrÃ©**, car certaines anomalies sont plus rares que dâ€™autres. Sa rÃ©partition est la suivante :  

| Classe  | Train Videos (nb) | Train Duration | Validation Videos (nb) | Validation Duration |
|---------|-----------------|----------------|-----------------------|-------------------|
| Fight   | 587             | 0h50           | 391                   | 0h31              |
| Fire    | 237             | 3h40           | 61                    | 0h46              |
| Shooting| 247             | 0h17           | 64                    | 0h08              |

![RÃ©partition des classes](chemin/vers/image_repartition.png)  

#### ğŸ–¼ï¸ PrÃ©-traitement et augmentation  

- Chaque vidÃ©o contenant une anomalie a Ã©tÃ© **dÃ©coupÃ©e manuellement** pour ne conserver que la portion pertinente.  
- Les vidÃ©os ont Ã©tÃ© chargÃ©es via un **video generator** (voir [repo GitHub](lien_vers_repo)) pour former des **sÃ©quences de 20 images de taille 112x122**.  
- Une **data augmentation rÃ©aliste** a Ã©tÃ© appliquÃ©e pour simuler des situations plausibles :  
  - Modification de la **luminositÃ©**  
  - **Flip horizontal**  
  - **Zoom**  

![Exemple de prÃ©-traitement et augmentation](chemin/vers/image_pretraitement.png)  


### 2ï¸âƒ£ Images pour la dÃ©tection dâ€™objets  

ConformÃ©ment au postulat de **combiner dÃ©tection dâ€™objets et dÃ©tection dâ€™anomalies**, nous avons crÃ©Ã© un **second jeu de donnÃ©es basÃ© sur des images**, ciblant les entitÃ©s prÃ©sentes Ã  lâ€™Ã©cran et liÃ©es aux anomalies.  

#### ğŸ·ï¸ Classes et volume

Les classes et volumes approximatifs sont les suivants :  
- **Armes Ã  feu** : ~10 000 images ğŸ”«  
- **Flammes** : >2 000 images ğŸ”¥  
- **Personnes** : chaque individu prÃ©sent dans les images ğŸ‘¤  

Des images **ne contenant aucune de ces classes** ont Ã©galement Ã©tÃ© ajoutÃ©es, pour lâ€™apprentissage et la validation, afin de mieux gÃ©rer les situations normales.  

#### ğŸ–¼ï¸ Annotation et utilisation

- Les images ont Ã©tÃ© **Ã©tiquetÃ©es manuellement**.

---

## ğŸ§  ModÃ¨le

Le systÃ¨me de dÃ©tection combine plusieurs architectures pour traiter les flux vidÃ©o Ã  la fois sur le **plan spatial** et le **plan temporel** :  

- **CNN + RNN** : utilisÃ© pour lâ€™**analyse temporelle** des sÃ©quences vidÃ©o.  
- **YOLOv3, YOLOv4, YOLOv7** : utilisÃ©s pour lâ€™**analyse spatiale** des images.  

![SchÃ©ma du systÃ¨me](chemin/vers/image_systeme.png)  

### ğŸ”„ Combinaison des modÃ¨les

Les modÃ¨les peuvent Ãªtre combinÃ©s de diffÃ©rentes maniÃ¨res :  
1. **SÃ©rie** : YOLO est utilisÃ© pour un **prÃ©-traitement spatial**, et ses rÃ©sultats sont ensuite transmis au CNN+RNN pour lâ€™analyse temporelle.  
2. **ParallÃ¨le** : les deux modÃ¨les effectuent simultanÃ©ment leur dÃ©tection, puis leurs rÃ©sultats sont **fusionnÃ©s** pour produire la prÃ©diction finale.  

Un **module dâ€™explicabilitÃ©** est Ã©galement intÃ©grÃ© pour analyser certaines prÃ©dictions, bien quâ€™il **ne fonctionne pas en temps rÃ©el**.  

### ğŸ–¥ CNN + RNN

- **CNN** : VGG19  
- **RNN** : GRU avec **1024 neurones**,
- suivi dâ€™un **MLP Ã  3 couches** (1024 â†’ 512 â†’ 128 neurones)  
  - **Dropout :** 50% sur toutes les couches  
  - **RÃ©gularisation L2 :** coefficient 0.01  
- **EntraÃ®nement** :  
  - Batch training sur nos vidÃ©os  
  - **200 epochs**  
  - Optimiseur : **Stochastic Gradient Descent (SGD)** avec **learning rate 0.01**

![SchÃ©ma CNN + RNN](chemin/vers/image_CNN_RNN.png)  

### ğŸ–¼ YOLO

Les modÃ¨les **YOLOv3, YOLOv4 et YOLOv7** ont Ã©tÃ© **re-entraÃ®nÃ©s sur notre jeu de donnÃ©es dâ€™images**, permettant une dÃ©tection adaptÃ©e aux classes dÃ©finies dans notre dataset.

---

## ğŸ“ˆ RÃ©sultats

---

## âš ï¸ Limitations

- **Nombre limitÃ© de classes** : seules quelques classes ont Ã©tÃ© traitÃ©es, car la collecte et la labellisation des donnÃ©es sont longues et coÃ»teuses.
  
- **Pas de comparaison avec dâ€™autres architectures** : le projet ne permet pas de benchmark direct avec des solutions existantes.
  
- **Technologies non utilisÃ©es** : les auto-encodeurs ou Vision Transformers nâ€™ont pas Ã©tÃ© explorÃ©s, faute de temps et de puissance, de plus ces architectures ne sont pas toujours adaptÃ©es au traitement en **temps rÃ©el**.

---

## ğŸ“š Publications / Articles

### ğŸ“ ThÃ¨ses

- ğŸ‡«ğŸ‡· **DÃ©tection dâ€™anomalies en temps rÃ©el dans un flux vidÃ©o** (2023)  
  Auteur : F. Poirier  
  [Lien HAL](https://hal.science/tel-04792952)  

- ğŸ‡¬ğŸ‡§ **Real-Time Anomaly Detection in Video Streams** (2023)  
  Auteur : F. Poirier  
  ThÃ¨se traduite  
  [Lien HAL](https://hal.science/tel-04824941)  



### ğŸ“ Articles scientifiques

- ğŸ‡¬ğŸ‡§ **From CNN to CNN RNN Adapting Visualization Techniques for Time-Series Anomaly Detection** (2025, soumis)  
  Auteurs : F. Poirier, M. Lamolle  
  En cours de soumission au journal *Engineering Applications of Artificial Intelligence*
  
- ğŸ‡¬ğŸ‡§ **From CNN to CNN+ RNN: Adapting Visualization Techniques for Time-Series Anomaly Detection** (2024)  
  Auteur : F. Poirier  
  [Lien ArXiv](https://arxiv.org/abs/2411.04707)  

- ğŸ‡¬ğŸ‡§ **Real-Time Anomalies Detection on Video** (2024)  
  Auteur : F. Poirier  
  [Lien ArXiv](https://arxiv.org/abs/2410.18051)  

- ğŸ‡¬ğŸ‡§ **Hybrid Architecture for Real-Time Video Anomaly Detection: Integrating Spatial and Temporal Analysis** (2024)  
  Auteur : F. Poirier  
  [Lien ArXiv](https://arxiv.org/abs/2410.15909)  

- ğŸ‡¬ğŸ‡§ **Enhancing Anomaly Detection in Videos using a Combined YOLO and a VGG GRU Approach** (2023)  
  Auteurs : F. Poirier, R. Jaziri, C. Srour, G. Bernard  
  ConfÃ©rence : 20th ACS/IEEE International Conference on Computer Systems and Applications (AICCSA)  
  [Lien IEEE](https://ieeexplore.ieee.org/abstract/document/10479307)  

- ğŸ‡«ğŸ‡· **DÃ©tection dâ€™anomalies en temps rÃ©el dans le flux vidÃ©o** (2022)  
  Auteurs : F. Poirier, R. Jaziri, C. Srour, G. Bernard  
  [Lien HAL](https://hal.science/hal-04810781)  



### ğŸ† Posters et distinctions

- ğŸ‡«ğŸ‡· **DÃ©tection dâ€™anomalies en temps rÃ©el dans le flux vidÃ©o**  
  Poirier Fabien, R. Jaziri, C. Srour, G. Bernard  
  Poster prÃ©sentÃ© Ã  EGC 2022  
  [Lien HAL](https://hal.science/hal-04830165v1/document)  
  ğŸ… **Prix de la Meilleure DÃ©monstration** EGC 2022


